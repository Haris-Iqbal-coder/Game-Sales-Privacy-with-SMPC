{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOvQI6ZM4IlE"
      },
      "source": [
        "# Analysis of Video Game Sales\n",
        "\n",
        " This project explores the application of Secure Multi-Party Computation (SMPC) techniques in analyzing video game sales data. Our objective is to analyze and gain insights without compromising the confidentiality of the data. By implementing techniques like Paillier Encryption, Differential Privacy (DP), and Advanced Encryption Standard (AES), we aim to showcase a privacy-preserving approach to data analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4bdzNDS3rtT"
      },
      "source": [
        "**Note:** To analyze the video game sales data, we are using a CSV file named `vgsales.csv`.\n",
        "\n",
        "Ensure that the `vgsales.csv` file is located in the same directory as your Jupyter notebook or Python script. If it's in a different directory, you'll need to specify the correct path when loading the file.\n",
        "\n",
        "Remember to execute each cell in sequence if you're using a Jupyter notebook, as some cells may depend on the execution of previous ones.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I4YSU-p2HZX"
      },
      "source": [
        "To perform cryptographic functions such as encryption and decryption in our analysis, we need to install the `pycryptodome` library. This library provides various cryptographic modules that are essential for securing data. You can install it using the following pip command:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbmtU9ysv2rK"
      },
      "outputs": [],
      "source": [
        " pip install pycryptodome"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4F3Cojm2Xri"
      },
      "source": [
        "`pycryptodomex` is an another self-contained Python package of low-level cryptographic primitives. Install it using the pip command as follows:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzqUBLAguGI7"
      },
      "outputs": [],
      "source": [
        "pip install pycryptodomex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-bZ7IPa3MCC"
      },
      "outputs": [],
      "source": [
        "pip install phe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz95-HxYKeUm"
      },
      "source": [
        "Importing useful libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-Lxxor3ErZOY"
      },
      "outputs": [],
      "source": [
        "from phe import paillier\n",
        "from Cryptodome.Cipher import AES\n",
        "from Crypto.Random import get_random_bytes\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import laplace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_BtnoxRH2DI"
      },
      "source": [
        "## Part 1: Average sales per decade (1980-2020)\n",
        "\n",
        "In this part, we aim to determine which geographical region (North America, Europe, or the Rest of the World) experienced the highest average video game sales per decade, spanning from 1980 to 2020. Then we plot the results for better comparison.\n",
        "\n",
        "To ensure the privacy and security of the data, we employ **Paillier Encryption**. This homomorphic encryption technique allows us to perform calculations on encrypted data, guaranteeing that the average number of sales is securely computed while maintaining the confidentiality of individual game sales data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PyQYxogL80Ld"
      },
      "outputs": [],
      "source": [
        "# Reading the CSV file\n",
        "df = pd.read_csv('vgsales.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8Q7gIrnBEKI"
      },
      "outputs": [],
      "source": [
        "# Function modification for batch processing\n",
        "def paillier_avg_batch(numbers, batch_size=100):\n",
        "    public_key, private_key = paillier.generate_paillier_keypair()\n",
        "    n_batches = len(numbers) // batch_size\n",
        "\n",
        "    encrypted_sum = 0\n",
        "    for i in range(n_batches):\n",
        "        batch_total = sum(numbers[i*batch_size:(i+1)*batch_size])\n",
        "        encrypted_sum += public_key.encrypt(batch_total)\n",
        "\n",
        "    # Handle the remainder if the dataset size is not divisible by batch_size\n",
        "    if len(numbers) % batch_size != 0:\n",
        "        batch_total = sum(numbers[n_batches*batch_size:])\n",
        "        encrypted_sum += public_key.encrypt(batch_total)\n",
        "\n",
        "    decrypted_sum = private_key.decrypt(encrypted_sum)\n",
        "    avg = decrypted_sum / len(numbers)\n",
        "    return avg\n",
        "\n",
        "def decade_ranges(year):\n",
        "    if 1980 <= year < 1990:\n",
        "        return \"1980-1990\"\n",
        "    elif 1990 <= year < 2000:\n",
        "        return \"1990-2000\"\n",
        "    elif 2000 <= year < 2010:\n",
        "        return \"2000-2010\"\n",
        "    elif 2010 <= year <= 2020:\n",
        "        return \"2010-2020\"\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "# Add a new column for the decade\n",
        "df['DecadeRange'] = df['Year'].apply(decade_ranges)\n",
        "\n",
        "# Group the data by decade\n",
        "grouped_data = df[df['DecadeRange'].notna()].groupby('DecadeRange')\n",
        "\n",
        "decade_avgs = {}\n",
        "for decade_range, group in grouped_data:\n",
        "    na_avg = round(paillier_avg_batch(group['NA_Sales'], batch_size=100), 2)\n",
        "    eu_avg = round(paillier_avg_batch(group['EU_Sales'], batch_size=100), 2)\n",
        "    rest_of_world_avg = round(paillier_avg_batch(group['Global_Sales'], batch_size=100), 2)\n",
        "\n",
        "\n",
        "    decade_avgs[decade_range] = {\n",
        "        'NA': na_avg,\n",
        "        'EU': eu_avg,\n",
        "        'Rest of the World': rest_of_world_avg\n",
        "    }\n",
        "\n",
        "for decade_range in sorted(decade_avgs.keys()):\n",
        "    print(f\"Decade: {decade_range}\")\n",
        "    print(f\"  NA Average Sales: {decade_avgs[decade_range]['NA']} million\")\n",
        "    print(f\"  EU Average Sales: {decade_avgs[decade_range]['EU']} million\")\n",
        "    print(f\"  Rest of World Average Sales: {decade_avgs[decade_range]['Rest of the World']} million\\n\")\n",
        "\n",
        "plot_data = []\n",
        "for decade_range, sales in decade_avgs.items():\n",
        "    for region, avg_sales in sales.items():\n",
        "        plot_data.append({'DecadeRange': decade_range, 'Region': region, 'Average Sales': avg_sales})\n",
        "\n",
        "# Convert plot_data to a DataFrame\n",
        "df_plot = pd.DataFrame(plot_data)\n",
        "\n",
        "# Create the line graph\n",
        "fig = px.line(df_plot, x=\"DecadeRange\", y=\"Average Sales\", color=\"Region\",\n",
        "              title=\"Average Video Game Sales per Decade Range (in millions)\",\n",
        "              labels={\"DecadeRange\": \"Decade Range\", \"Average Sales\": \"Average Sales (Millions)\"})\n",
        "\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCHDIyMi2xKV"
      },
      "source": [
        "# Part 2: Ranking Top 5 Favorite Games in Each Region\n",
        "\n",
        "In this part, we rank the top 5 favorite games in each region based on their sales figures. To protect the privacy of individual sales data, we apply **Differential Privacy (DP)** techniques by adding Laplace noise to the sales figures. This ensures the confidentiality of the dataset, adhering to privacy-preserving measures.\n",
        "\n",
        "\n",
        "First, we plot a bar graph showing top 5 favorite games in each region without adding any privacy measure to it.\n",
        "\n",
        "However, it is important to note that the introduction of noise means that the exact order of rankings may vary, especially with bigger values of the privacy budget epsilon (ε). Therefore, we conducted an analysis to understand the computational implications of applying DP with a wide range of ε values. Specifically, we observed how the computation time varies when ε ranges from 1 to nearly 100,000. Our findings indicate that as ε increases, so does the computation time. This is because a larger ε corresponds to a smaller noise scale, which requires less complex calculations.\n",
        "\n",
        "For our analysis, we have chosen an ε of 1. This provides a moderate level of noise that sufficiently anonymizes the data while preserving its utility. It also allows for faster computation, which is beneficial for processing large datasets.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPwyX4zN2yXX"
      },
      "outputs": [],
      "source": [
        "barWidth = 0.25\n",
        "\n",
        "list_sales = df.nlargest(5, ['NA_Sales'])\n",
        "list_sales_NA = list_sales['NA_Sales'].tolist()\n",
        "\n",
        "list_sales_1 = df.nlargest(5, ['EU_Sales'])\n",
        "list_sales_EU = list_sales_1['EU_Sales'].tolist()\n",
        "\n",
        "list_sales_2 = df.nlargest(5, ['Global_Sales'])\n",
        "list_sales_Other = list_sales_2['Global_Sales'].tolist()\n",
        "\n",
        "\n",
        "# Set the positions for the bars\n",
        "pos1 = np.arange(len(list_sales_NA))\n",
        "pos2 = [x + barWidth for x in pos1]\n",
        "pos3 = [x + barWidth for x in pos2]\n",
        "\n",
        "# Set figure size\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Create the horizontal bars\n",
        "barNA = plt.barh(pos1, list_sales_NA, height=barWidth, color='r', edgecolor='grey', label='NA')\n",
        "barEU = plt.barh(pos2, list_sales_EU, height=barWidth, color='g', edgecolor='grey', label='EU')\n",
        "barOther = plt.barh(pos3, list_sales_Other, height=barWidth, color='b', edgecolor='grey', label='Rest of the World')\n",
        "\n",
        "# Label the bars with game names\n",
        "for bar, name in zip(barNA, list_sales['Name']):\n",
        "    plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, ' '+name, va='center', ha='left', color='black', fontweight='bold')\n",
        "for bar, name in zip(barEU, list_sales_1['Name']):\n",
        "    plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, ' '+name, va='center', ha='left', color='black', fontweight='bold')\n",
        "for bar, name in zip(barOther, list_sales_2['Name']):\n",
        "    plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, ' '+name, va='center', ha='left', color='black', fontweight='bold')\n",
        "\n",
        "# Set the y-axis labels\n",
        "plt.yticks([r + barWidth for r in range(len(list_sales_NA))], ['Top 1', 'Top 2', 'Top 3', 'Top 4', 'Top 5'])\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel('Sales (Millions)')\n",
        "plt.title('Top 5 Favorite Games in Each Region')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRguZ_e327cJ"
      },
      "source": [
        "The graph below illustrates the relationship between ε values and computation time, reinforcing our choice of ε for our DP implementation.\n",
        "\n",
        "Note: We only considered NA sales just to show the impact of ε values on time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwXA3QkDAsF3"
      },
      "outputs": [],
      "source": [
        "ran_val = []\n",
        "for i in range(1,100000) :\n",
        "    ran_val.append(i)\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "list_saless = df.nlargest(5, ['NA_Sales'])\n",
        "list_NAA = list_saless['NA_Sales'].tolist()\n",
        "\n",
        "#sorted_check = []\n",
        "for i in range(1,10) :\n",
        "    ran_lap = random.choice(ran_val)\n",
        "    x.append(ran_lap)\n",
        "\n",
        "    list_NAA_change = []\n",
        "    start = time.time()\n",
        "    for j in range(len(list_NAA)) :\n",
        "        list_NAA[j] = (list_NAA[j]) + (1/ran_lap)\n",
        "    end = time.time()\n",
        "    y.append(end-start)\n",
        "list_time = []\n",
        "for i in range(len(y)):\n",
        "    ls = []\n",
        "    ls.append(x[i])\n",
        "    ls.append(y[i])\n",
        "    list_time.append(ls)\n",
        "\n",
        "x.clear()\n",
        "y.clear()\n",
        "list_time.sort()\n",
        "for i in range(len(list_time)):\n",
        "    x.append(list_time[i][0])\n",
        "    y.append(list_time[i][1])\n",
        "\n",
        "#print(x)\n",
        "plt.plot(x,y)\n",
        "plt.xlabel(\"Value of epsilon (ε)\")\n",
        "plt.ylabel(\"Computation Time (s)\")\n",
        "plt.title(\"Computation Time for Adding Laplace Noise\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rHYtLAaHWXr"
      },
      "source": [
        "Below is the bar graph representing the top 5 favorite games in each region after applying DP with ε = 1.\n",
        "\n",
        "This visualization demonstrates the effect of DP on our dataset. Note that the names of the games remain constant, as our primary focus is on demonstrating the impact of DP on the sales figures, not on the actual titles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SAN6EOU2753"
      },
      "outputs": [],
      "source": [
        "# Add Laplace noise to the sales figures for differential privacy\n",
        "epsilon = 1  # Setting Privacy Budget\n",
        "list_sales_NA = [sale + np.random.laplace(0, epsilon) for sale in list_sales_NA]\n",
        "list_sales_EU = [sale + np.random.laplace(0, epsilon) for sale in list_sales_EU]\n",
        "list_sales_Other = [sale + np.random.laplace(0, epsilon) for sale in list_sales_Other]\n",
        "\n",
        "# Set the positions for the bars\n",
        "pos1 = np.arange(len(list_sales_NA))\n",
        "pos2 = [x + barWidth for x in pos1]\n",
        "pos3 = [x + barWidth for x in pos2]\n",
        "\n",
        "label_position = max(max(list_sales_NA), max(list_sales_EU), max(list_sales_Other)) * 0.09  # 5% of the maximum sales\n",
        "\n",
        "# Set figure size\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Create the horizontal bars\n",
        "plt.barh(pos1, list_sales_NA, height=barWidth, color='r', edgecolor='grey', label='NA')\n",
        "plt.barh(pos2, list_sales_EU, height=barWidth, color='g', edgecolor='grey', label='EU')\n",
        "plt.barh(pos3, list_sales_Other, height=barWidth, color='b', edgecolor='grey', label='Rest of the World')\n",
        "\n",
        "for idx, name in enumerate(list_sales['Name']):\n",
        "    plt.text(label_position, pos1[idx], ' '+name, va='center', ha='left', color='black', fontweight='bold')\n",
        "for idx, name in enumerate(list_sales_1['Name']):\n",
        "    plt.text(label_position, pos2[idx], ' '+name, va='center', ha='left', color='black', fontweight='bold')\n",
        "for idx, name in enumerate(list_sales_2['Name']):\n",
        "    plt.text(label_position, pos3[idx], ' '+name, va='center', ha='left', color='black', fontweight='bold')\n",
        "\n",
        "# Set the y-axis labels in ascending order\n",
        "plt.yticks([r + barWidth for r in range(len(list_sales_NA))], ['Top 1', 'Top 2', 'Top 3', 'Top 4', 'Top 5'])\n",
        "\n",
        "# Invert the y-axis to have the top game at the top\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel('Sales (Millions)')\n",
        "plt.title('Top 5 Favorite Games in Each Region with Differential Privacy (ε = 1)')\n",
        "plt.legend()\n",
        "\n",
        "# Print the noisy sales data\n",
        "print(\"Noisy NA Sales:\", list_sales_NA)\n",
        "print(\"Noisy EU Sales:\", list_sales_EU)\n",
        "print(\"Noisy Other Sales:\", list_sales_Other)\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBK7eMwLJF5h"
      },
      "source": [
        "# Part 3: Accuracy Analysis of DP on Game Rankings\n",
        "\n",
        "In this part, we do accuracy analysis of DP's impact on game rankings for each region. For the sake of clear visualization and to effectively demonstrate the impact of differential privacy, we have limited our analysis to the top 500 games. This focused approach allows us to more easily observe the changes in rankings due to noise addition and avoids overwhelming the graph with too many data points, which can make patterns and insights difficult to discern.\n",
        "\n",
        "The scatter plots below show the change in ranking for each of these top 500 games. The x-axis represents the original ranking based on actual sales, while the y-axis indicates how much each game's rank has changed after the application of noise. A greater change in rank suggests a more significant impact of the noise on the game's sales figure, highlighting the trade-off between privacy and data accuracy.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOQ39s-DL9Uf"
      },
      "outputs": [],
      "source": [
        "# Get the top 500 games in the NA region\n",
        "top_500 = df.nlargest(500, ['NA_Sales'])\n",
        "original_sales = top_500['NA_Sales'].tolist()\n",
        "original_names = top_500['Name'].tolist()\n",
        "\n",
        "# Apply Laplace noise to the sales figures for differential privacy\n",
        "epsilon = 1\n",
        "noisy_sales = [sale + np.random.laplace(0, epsilon) for sale in original_sales]\n",
        "\n",
        "# Sort the original and noisy sales\n",
        "sorted_indices_original = sorted(range(len(original_sales)), key=original_sales.__getitem__, reverse=True)\n",
        "sorted_indices_noisy = sorted(range(len(noisy_sales)), key=noisy_sales.__getitem__, reverse=True)\n",
        "\n",
        "# Map the original and noisy indices to their ranks\n",
        "original_ranks = {original_names[idx]: rank for rank, idx in enumerate(sorted_indices_original)}\n",
        "noisy_ranks = {original_names[idx]: rank for rank, idx in enumerate(sorted_indices_noisy)}\n",
        "\n",
        "# Calculate the rank differences for each game\n",
        "x = []  # Original ranks\n",
        "y = []  # Rank differences\n",
        "\n",
        "for name in original_names:\n",
        "    original_rank = original_ranks[name]\n",
        "    noisy_rank = noisy_ranks[name]\n",
        "    x.append(original_rank)\n",
        "    y.append(abs(original_rank - noisy_rank))\n",
        "\n",
        "# Plot the rank differences for the top 500 games\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(x, y, alpha=0.6)  # Using a scatter plot for better visualization\n",
        "plt.title('DP Impact on Game Ranking for Top 500 Games (NA Region)')\n",
        "plt.xlabel('Original Rank')\n",
        "plt.ylabel('Change in Rank')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8t9fFD8PNm0"
      },
      "outputs": [],
      "source": [
        "# Get the top 500 games in the EU region\n",
        "top_500 = df.nlargest(500, ['EU_Sales'])\n",
        "original_sales = top_500['EU_Sales'].tolist()\n",
        "original_names = top_500['Name'].tolist()\n",
        "\n",
        "# Apply Laplace noise to the sales figures for differential privacy\n",
        "epsilon = 1\n",
        "noisy_sales = [sale + np.random.laplace(0, epsilon) for sale in original_sales]\n",
        "\n",
        "# Sort the original and noisy sales\n",
        "sorted_indices_original = sorted(range(len(original_sales)), key=original_sales.__getitem__, reverse=True)\n",
        "sorted_indices_noisy = sorted(range(len(noisy_sales)), key=noisy_sales.__getitem__, reverse=True)\n",
        "\n",
        "# Map the original and noisy indices to their ranks\n",
        "original_ranks = {original_names[idx]: rank for rank, idx in enumerate(sorted_indices_original)}\n",
        "noisy_ranks = {original_names[idx]: rank for rank, idx in enumerate(sorted_indices_noisy)}\n",
        "\n",
        "# Calculate the rank differences for each game\n",
        "x = []  # Original ranks\n",
        "y = []  # Rank differences\n",
        "\n",
        "for name in original_names:\n",
        "    original_rank = original_ranks[name]\n",
        "    noisy_rank = noisy_ranks[name]\n",
        "    x.append(original_rank)\n",
        "    y.append(abs(original_rank - noisy_rank))\n",
        "\n",
        "# Plot the rank differences for the top 500 games\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(x, y, alpha=0.6)  # Using a scatter plot for better visualization\n",
        "plt.title('DP Impact on Game Ranking for Top 500 Games (EU Region)')\n",
        "plt.xlabel('Original Rank')\n",
        "plt.ylabel('Change in Rank')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEoPowLyP5X1"
      },
      "outputs": [],
      "source": [
        "# Get the top 500 games in the rest of the world\n",
        "top_500 = df.nlargest(500, ['Global_Sales'])\n",
        "original_sales = top_500['Global_Sales'].tolist()\n",
        "original_names = top_500['Name'].tolist()\n",
        "\n",
        "# Apply Laplace noise to the sales figures for differential privacy\n",
        "epsilon = 1\n",
        "noisy_sales = [sale + np.random.laplace(0, epsilon) for sale in original_sales]\n",
        "\n",
        "# Sort the original and noisy sales\n",
        "sorted_indices_original = sorted(range(len(original_sales)), key=original_sales.__getitem__, reverse=True)\n",
        "sorted_indices_noisy = sorted(range(len(noisy_sales)), key=noisy_sales.__getitem__, reverse=True)\n",
        "\n",
        "# Map the original and noisy indices to their ranks\n",
        "original_ranks = {original_names[idx]: rank for rank, idx in enumerate(sorted_indices_original)}\n",
        "noisy_ranks = {original_names[idx]: rank for rank, idx in enumerate(sorted_indices_noisy)}\n",
        "\n",
        "# Calculate the rank differences for each game\n",
        "x = []  # Original ranks\n",
        "y = []  # Rank differences\n",
        "\n",
        "for name in original_names:\n",
        "    original_rank = original_ranks[name]\n",
        "    noisy_rank = noisy_ranks[name]\n",
        "    x.append(original_rank)\n",
        "    y.append(abs(original_rank - noisy_rank))\n",
        "\n",
        "# Plot the rank differences for the top 500 games\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(x, y, alpha=0.6)  # Using a scatter plot for better visualization\n",
        "plt.title('DP Impact on Game Ranking for Top 500 Games (Rest of the World)')\n",
        "plt.xlabel('Original Rank')\n",
        "plt.ylabel('Change in Rank')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUafvWJ9clBb"
      },
      "source": [
        "# Part 4: Analyzing Data with AES Encryption\n",
        "\n",
        "In this section, we uncover some interesting insights while ensuring the confidentiality of key categorical information. To achieve this, we employ Advanced Encryption Standard (AES) encryption to protect the details of game **platforms**, **genres**, and **publishers**.\n",
        "\n",
        "First, we encrypt the data, which is then decrypted only to reveal the final results. Post-analysis, the top platform, genre, and publisher are decrypted and displayed.\n",
        "\n",
        "This method allows us to conduct a thorough analysis while maintaining the integrity and confidentiality of the sensitive data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znFQNz6bfcUP"
      },
      "outputs": [],
      "source": [
        "file = open(\"vgsales.csv\",'r')\n",
        "start = 0\n",
        "list_title = []\n",
        "list_of_data =[]\n",
        "for line in file :\n",
        "    if start == 0 :\n",
        "        spl_line = line.split(',')\n",
        "        for val in spl_line :\n",
        "            list_title.append(val.strip())\n",
        "        start += 1\n",
        "    else :\n",
        "        spl_line = line.split(',')\n",
        "        if len(spl_line) == 11 :\n",
        "            ls = []\n",
        "            for val in spl_line :\n",
        "                ls.append(val.strip())\n",
        "            list_of_data.append(ls)\n",
        "\n",
        "\n",
        "def check_val (element) :\n",
        "    try:\n",
        "        float(element)\n",
        "    except ValueError:\n",
        "        return False\n",
        "    return True\n",
        "def aes(data) :\n",
        "    key = get_random_bytes(16)\n",
        "    cipher = AES.new(key, AES.MODE_EAX)\n",
        "    ciphertext, tag = cipher.encrypt_and_digest(data)\n",
        "    nonce = cipher.nonce\n",
        "    return ciphertext,tag,nonce,key\n",
        "\n",
        "\n",
        "ciphertext,tag,nonce,key = aes(b'10')\n",
        "ciphertext1,tag1,nonce1,key1 = aes(b'10')\n",
        "\n",
        "best_platform = {}\n",
        "best_publisher = {};\n",
        "best_genre = {}\n",
        "for index in range(len(list_of_data)) :\n",
        "    if check_val(list_of_data[index][6].strip()) and len(list_of_data[i]) == 11 :\n",
        "        if list_of_data[index][2] not in best_platform :\n",
        "            best_platform[list_of_data[index][2].strip()] = float(list_of_data[index][10])\n",
        "        else :\n",
        "            best_platform[list_of_data[index][2].strip()] += float(list_of_data[index][10])\n",
        "        if list_of_data[index][5] not in best_publisher :\n",
        "            # if list_of_data[index][5] not in best_publisher :\n",
        "            best_publisher[list_of_data[index][5].strip()] = float(list_of_data[index][10])\n",
        "        else:\n",
        "            best_publisher[list_of_data[index][5].strip()] += float(list_of_data[index][10])\n",
        "\n",
        "        if list_of_data[index][4] not in best_genre :\n",
        "            best_genre[list_of_data[index][4].strip()] = float(list_of_data[index][10])\n",
        "        else :\n",
        "            best_genre[list_of_data[index][4].strip()] += float(list_of_data[index][10])\n",
        "\n",
        "encypt_platform = []\n",
        "for key in best_platform :\n",
        "    encrypt_key =  bytes(key, 'utf-8')\n",
        "    ciphertext1,tag1,nonce1,key1 = aes(encrypt_key)\n",
        "    tup = (ciphertext1,tag1,nonce1,key1)\n",
        "    ls = []\n",
        "    ls.append(tup)\n",
        "    ls.append(best_platform[key])\n",
        "    encypt_platform.append(ls)\n",
        "\n",
        "max_val_platform = 0\n",
        "platform_tuple =()\n",
        "for i in range(len(encypt_platform)) :\n",
        "    if max_val_platform <encypt_platform[i][1] :\n",
        "        max_val_platform = encypt_platform[i][1]\n",
        "        platform_tuple = encypt_platform[i][0]\n",
        "\n",
        "ls_platform = []\n",
        "for x in platform_tuple :\n",
        "    ls_platform.append(x)\n",
        "#print(ls_platform[0])\n",
        "cipher = AES.new(ls_platform[3], AES.MODE_EAX, ls_platform[2])\n",
        "best_platform = cipher.decrypt_and_verify(ls_platform[0], ls_platform[1])\n",
        "print(f\"The most popular platform is: {best_platform}\")\n",
        "\n",
        "encrypt_publisher = []\n",
        "for key in best_publisher :\n",
        "   # print(key)\n",
        "    encrypt_key =  bytes(key, 'utf-8')\n",
        "    ciphertext1,tag1,nonce1,key1 = aes(encrypt_key)\n",
        "    tup = (ciphertext1,tag1,nonce1,key1)\n",
        "    ls = []\n",
        "    ls.append(tup)\n",
        "    ls.append(best_publisher[key])\n",
        "    encrypt_publisher.append(ls)\n",
        "\n",
        "max_val_publisher = 0\n",
        "publisher_tuple =()\n",
        "for i in range(len(encrypt_publisher)) :\n",
        "    if max_val_publisher <encrypt_publisher[i][1] :\n",
        "        max_val_publisher = encrypt_publisher[i][1]\n",
        "        publisher_tuple = encrypt_publisher[i][0]\n",
        "\n",
        "ls_publisher = []\n",
        "for x in publisher_tuple :\n",
        "    ls_publisher.append(x)\n",
        "# print(ls_publisher[0])\n",
        "cipher = AES.new(ls_publisher[3], AES.MODE_EAX, ls_publisher[2])\n",
        "best_publisher = cipher.decrypt_and_verify(ls_publisher[0], ls_publisher[1])\n",
        "print(f\"The most popular publisher is: {best_publisher}\")\n",
        "\n",
        "\n",
        "\n",
        "encypt_genre = []\n",
        "for key in best_genre :\n",
        "    encrypt_key =  bytes(key, 'utf-8')\n",
        "    ciphertext1,tag1,nonce1,key1 = aes(encrypt_key)\n",
        "    tup = (ciphertext1,tag1,nonce1,key1)\n",
        "    ls = []\n",
        "    ls.append(tup)\n",
        "    ls.append(best_genre[key])\n",
        "    encypt_genre.append(ls)\n",
        "\n",
        "max_val_genre = 0\n",
        "genre_tuple =()\n",
        "for i in range(len(encypt_genre)) :\n",
        "    if max_val_genre < encypt_genre[i][1] :\n",
        "        max_val_genre = encypt_genre[i][1]\n",
        "        genre_tuple = encypt_genre[i][0]\n",
        "\n",
        "ls_genre = []\n",
        "for x in genre_tuple :\n",
        "    ls_genre.append(x)\n",
        "#print(ls_genre[2])\n",
        "cipher = AES.new(ls_genre[3], AES.MODE_EAX, ls_genre[2])\n",
        "best_genre = cipher.decrypt_and_verify(ls_genre[0], ls_genre[1])\n",
        "print(f\"The most popular genre is: {best_genre}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
